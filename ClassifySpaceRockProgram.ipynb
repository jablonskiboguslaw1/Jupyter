{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('myenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d36641419b0a1f90b65c0d1d61349cf0022ec3dd079dd7312a2f80b1187bacf8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Tells the machine what folder contains the image data.\n",
    "data_dir = './Data'\n",
    "\n",
    "# Function to read the data; crop and resize the images; and then split it into test and train chunks.\n",
    "def load_split_train_test(datadir, valid_size = .2):\n",
    "    # This line of code transforms the images.\n",
    "    train_transforms = transforms.Compose([\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.Resize(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                          transforms.Resize(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                      ])\n",
    "\n",
    "    train_data = datasets.ImageFolder(datadir, transform=t\n",
    "    rain_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n",
    "\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# We're using 20% of data for testing.\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "print(trainloader.dataset.classes)\n",
    "\n",
    "\n",
    "# Transform the new image into numbers and resize it.\n",
    "test_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                    ])\n",
    "\n",
    "# A function to randomly select a set of images.\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels\n",
    "\n",
    "    # How many images do you want to see? It's set to 5, but you can change the number.\n",
    "images, labels = get_random_images(5)\n",
    "to_pil = transforms.ToPILImage()\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "classes=trainloader.dataset.classes\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Builds all the neurons.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# The parameters of our deep learning model.\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 2),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)\n",
    "print('done')\n",
    "epochs = 5\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "\n",
    "        steps += 1\n",
    "        print('Training step ', steps)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n",
    "print(accuracy/len(testloader))\n",
    "torch.save(model, 'aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}